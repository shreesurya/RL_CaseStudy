{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cab-Driver Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from collections import deque\n",
    "import collections\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "# for building DQN model\n",
    "from keras import layers\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# for plotting graphs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import the environment\n",
    "from Cab_env import CabDriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Time Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7., 7., 7., 7., 7., 7., 4., 4., 4., 4., 4., 4., 2., 2., 2., 2., 2.,\n",
       "       2., 8., 8., 8., 8., 8., 8.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the time matrix provided\n",
    "Time_matrix = np.load(\"TM.npy\")\n",
    "Time_matrix[1,2,:,6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracking the state-action pairs for checking convergence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "States_track = collections.defaultdict(dict)\n",
    "print(len(States_track))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise states to be tracked\n",
    "def initialise_tracking_states():\n",
    "    sample_q_values = [((0, 0, 0), (0,1)), ((0, 0, 0), (0,2))]    \n",
    "    for q_values in sample_q_values:\n",
    "        state = q_values[0]\n",
    "        action = q_values[1]\n",
    "        States_track[state][action] = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a function to save the Q-dictionary as a pickle file\n",
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent Class\n",
    "\n",
    "If you are using this framework, you need to fill the following to complete the following code block:\n",
    "1. State and Action Size\n",
    "2. Hyperparameters\n",
    "3. Create a neural-network model in function 'build_model()'\n",
    "4. Define epsilon-greedy strategy in function 'get_action()'\n",
    "5. Complete the function 'append_sample()'. This function appends the recent experience tuple <state, action, reward, new-state> to the memory\n",
    "6. Complete the 'train_model()' function with following logic:\n",
    "   - If the memory size is greater than mini-batch size, you randomly sample experiences from memory as per the mini-batch size and do the following:\n",
    "      - Initialise your input and output batch for training the model\n",
    "      - Calculate the target Q value for each sample: reward + gamma*max(Q(s'a,))\n",
    "      - Get Q(s', a) values from the last trained model\n",
    "      - Update the input batch as your encoded state-action and output batch as your Q-values\n",
    "      - Then fit your DQN model using the updated input and output batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture Detail:\n",
    "### - The input to the NN is only the state and its output is the Q-value of every possible action. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size, discount_factor=0.95, learning_rate=0.001,\n",
    "                 epsilon=1, epsilon_decay=0.0003, epsilon_min=0.00001):\n",
    "        # Define size of state and action\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "\n",
    "        # Write here: Specify you hyper parameters for the DQN\n",
    "        self.discount_factor = discount_factor\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epsilon_max = epsilon\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.epsilon_min = epsilon_min\n",
    "\n",
    "        self.batch_size = 32\n",
    "        # create replay memory using deque\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        \n",
    "        # Initialize the value of the states tracked\n",
    "        self.states_tracked = []\n",
    "        self.track_state = np.array(env.state_encod_arch1([0,0,0])).reshape(1, 36)\n",
    "\n",
    "        # create main model and target model\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    # approximate Q function using Neural Network\n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        # Write your code here: Add layers to your neural nets   \n",
    "        # hidden layers\n",
    "        model.add(Dense(32, input_dim=self.state_size, activation='relu',\n",
    "                        kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(32, activation='relu', kernel_initializer='he_uniform'))\n",
    "\n",
    "        # the output layer: output is of size num_actions\n",
    "        model.add(Dense(self.action_size, activation='relu', kernel_initializer='he_uniform'))\n",
    "\n",
    "        model.compile(loss='mse', optimizer=Adam(lr=self.learning_rate))\n",
    "        model.summary\n",
    "        return model\n",
    "\n",
    "    def get_action(self, state, action_space, possible_actions_index):\n",
    "        # Write your code here:\n",
    "        # get action from model using epsilon-greedy policy\n",
    "        # Decay in Îµ after we generate each sample from the environment\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            # explore: choose a random action from all possible actions\n",
    "            # in case of cartpole this will randomly choose an action between 0 and 1\n",
    "            index = random.randrange(len(possible_actions_index))\n",
    "            action_index = possible_actions_index[index]\n",
    "            action = action_space[action_index]\n",
    "            return action_index, action\n",
    "\n",
    "        else:\n",
    "            # choose the action with the highest q(s, a)\n",
    "            # the first index corresponds to the batch size, so\n",
    "            # reshape state to (1, state_size) so that the first index corresponds to the batch size\n",
    "\n",
    "            state = np.array(state).reshape(1, self.state_size)\n",
    "            q_value = self.model.predict(state)\n",
    "            #print(\"action picked from compile model = {}\".format(q_value))\n",
    "\n",
    "            return np.argmax(q_value[0]), action_space[np.argmax(q_value[0])]\n",
    "\n",
    "    def append_sample(self, state, action, reward, next_state):\n",
    "        # Write your code here:\n",
    "        # save sample <s,a,r,s'> to the replay memory\n",
    "        self.memory.append((state, action, reward, next_state))\n",
    "\n",
    "    # pick samples randomly from replay memory (with batch_size) and train the network\n",
    "    def train_model(self):\n",
    "        # print(\"trying training model\")\n",
    "        if len(self.memory) > self.batch_size:\n",
    "            # Sample batch from the memory\n",
    "            mini_batch = random.sample(self.memory, self.batch_size)\n",
    "\n",
    "            update_output = np.zeros((self.batch_size, self.state_size))  # write here\n",
    "            update_input = np.zeros((self.batch_size, self.state_size))  # write here\n",
    "\n",
    "            actions, rewards = [], []\n",
    "\n",
    "            for i in range(self.batch_size):\n",
    "                state, action, reward, next_state = mini_batch[i]\n",
    "                update_input[i] = state\n",
    "                actions.append(action)\n",
    "                rewards.append(reward)\n",
    "                update_output[i] = next_state\n",
    "\n",
    "                # Write your code from here\n",
    "                # 1. Predict the target from earlier model\n",
    "                target = self.model.predict(update_input)\n",
    "\n",
    "                # 2. Get the target for the Q-network\n",
    "                target_qval = self.model.predict(update_output)\n",
    "\n",
    "                # 3. Update your 'update_output' and 'update_input' batch\n",
    "            for i in range(self.batch_size):\n",
    "                ### do we need to handle terminal state. termination function here is independent\n",
    "                #  from actions and state so we can ignore it\n",
    "\n",
    "                target[i][actions[i]] = rewards[i] + self.discount_factor * np.max(target_qval[i])\n",
    "            # 4. Fit your model and track the loss values\n",
    "            self.model.fit(update_input, target, batch_size=self.batch_size, epochs=1, verbose=0)\n",
    "    \n",
    "    def store_q_values(self):\n",
    "        \"\"\" We are keeping track of q value for state [0,0,0] and action (0,2)\"\"\"\n",
    "        q_value = self.model.predict(self.track_state)\n",
    "        self.states_tracked.append(q_value[0][2])\n",
    "            \n",
    "    def save(self, name):\n",
    "        self.model.save(name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Episodes = 20000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DQN block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrie\\Anaconda3\\envs\\tfod\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 0, reward -129.0, memory_length 141, epsilon 1.0\n",
      "INFO:tensorflow:Assets written to: model.pkl\\assets\n",
      "Total time taken  446.012024641037\n",
      "state terminated\n",
      "episode 1, reward -506.0, memory_length 279, epsilon 0.9997000479950504\n",
      "state terminated\n",
      "episode 2, reward -51.0, memory_length 425, epsilon 0.9994001859622058\n",
      "state terminated\n",
      "episode 3, reward -133.0, memory_length 561, epsilon 0.9991004138744786\n",
      "state terminated\n",
      "episode 4, reward -351.0, memory_length 720, epsilon 0.9988007317048893\n",
      "state terminated\n",
      "episode 5, reward -509.0, memory_length 878, epsilon 0.9985011394264665\n",
      "state terminated\n",
      "episode 6, reward -288.0, memory_length 1024, epsilon 0.998201637012247\n",
      "state terminated\n",
      "episode 7, reward -312.0, memory_length 1200, epsilon 0.9979022244352754\n",
      "state terminated\n",
      "episode 8, reward -410.0, memory_length 1348, epsilon 0.9976029016686048\n",
      "state terminated\n",
      "episode 9, reward -315.0, memory_length 1484, epsilon 0.997303668685296\n",
      "state terminated\n",
      "episode 10, reward -351.0, memory_length 1655, epsilon 0.997004525458418\n",
      "state terminated\n",
      "episode 11, reward -72.0, memory_length 1810, epsilon 0.9967054719610479\n",
      "state terminated\n",
      "episode 12, reward -180.0, memory_length 1953, epsilon 0.996406508166271\n",
      "state terminated\n",
      "episode 13, reward -144.0, memory_length 2000, epsilon 0.9961076340471806\n",
      "state terminated\n",
      "episode 14, reward -559.0, memory_length 2000, epsilon 0.9958088495768779\n",
      "state terminated\n",
      "episode 15, reward -108.0, memory_length 2000, epsilon 0.9955101547284723\n",
      "state terminated\n",
      "episode 16, reward -169.0, memory_length 2000, epsilon 0.9952115494750813\n",
      "state terminated\n",
      "episode 17, reward -259.0, memory_length 2000, epsilon 0.9949130337898304\n",
      "state terminated\n",
      "episode 18, reward -93.0, memory_length 2000, epsilon 0.9946146076458533\n",
      "state terminated\n",
      "episode 19, reward -393.0, memory_length 2000, epsilon 0.9943162710162915\n",
      "state terminated\n",
      "episode 20, reward -333.0, memory_length 2000, epsilon 0.9940180238742947\n",
      "state terminated\n",
      "episode 21, reward 44.0, memory_length 2000, epsilon 0.9937198661930208\n",
      "state terminated\n",
      "episode 22, reward -29.0, memory_length 2000, epsilon 0.9934217979456356\n",
      "state terminated\n",
      "episode 23, reward -585.0, memory_length 2000, epsilon 0.9931238191053128\n",
      "state terminated\n",
      "episode 24, reward -302.0, memory_length 2000, epsilon 0.9928259296452343\n",
      "state terminated\n",
      "episode 25, reward 22.0, memory_length 2000, epsilon 0.9925281295385903\n",
      "state terminated\n",
      "episode 26, reward -153.0, memory_length 2000, epsilon 0.9922304187585785\n",
      "state terminated\n",
      "episode 27, reward -401.0, memory_length 2000, epsilon 0.9919327972784051\n",
      "state terminated\n",
      "episode 28, reward -57.0, memory_length 2000, epsilon 0.9916352650712842\n",
      "state terminated\n",
      "episode 29, reward -294.0, memory_length 2000, epsilon 0.9913378221104377\n",
      "state terminated\n",
      "episode 30, reward -88.0, memory_length 2000, epsilon 0.9910404683690959\n",
      "state terminated\n",
      "episode 31, reward 16.0, memory_length 2000, epsilon 0.990743203820497\n",
      "state terminated\n",
      "episode 32, reward -236.0, memory_length 2000, epsilon 0.9904460284378871\n",
      "state terminated\n",
      "episode 33, reward -172.0, memory_length 2000, epsilon 0.9901489421945203\n",
      "state terminated\n",
      "episode 34, reward 49.0, memory_length 2000, epsilon 0.989851945063659\n",
      "state terminated\n",
      "episode 35, reward -101.0, memory_length 2000, epsilon 0.9895550370185736\n",
      "state terminated\n",
      "episode 36, reward -501.0, memory_length 2000, epsilon 0.9892582180325421\n",
      "state terminated\n",
      "episode 37, reward -96.0, memory_length 2000, epsilon 0.9889614880788508\n",
      "state terminated\n",
      "episode 38, reward -29.0, memory_length 2000, epsilon 0.9886648471307942\n",
      "state terminated\n",
      "episode 39, reward -414.0, memory_length 2000, epsilon 0.9883682951616745\n",
      "state terminated\n",
      "episode 40, reward -226.0, memory_length 2000, epsilon 0.9880718321448019\n",
      "state terminated\n",
      "episode 41, reward -115.0, memory_length 2000, epsilon 0.987775458053495\n",
      "state terminated\n",
      "episode 42, reward -113.0, memory_length 2000, epsilon 0.98747917286108\n",
      "state terminated\n",
      "episode 43, reward -99.0, memory_length 2000, epsilon 0.987182976540891\n",
      "state terminated\n",
      "episode 44, reward 21.0, memory_length 2000, epsilon 0.9868868690662709\n",
      "state terminated\n",
      "episode 45, reward -32.0, memory_length 2000, epsilon 0.9865908504105695\n",
      "state terminated\n",
      "episode 46, reward -256.0, memory_length 2000, epsilon 0.9862949205471453\n",
      "state terminated\n",
      "episode 47, reward -252.0, memory_length 2000, epsilon 0.9859990794493647\n",
      "state terminated\n",
      "episode 48, reward -195.0, memory_length 2000, epsilon 0.9857033270906017\n",
      "state terminated\n",
      "episode 49, reward -327.0, memory_length 2000, epsilon 0.985407663444239\n",
      "state terminated\n",
      "episode 50, reward -162.0, memory_length 2000, epsilon 0.9851120884836666\n",
      "state terminated\n",
      "episode 51, reward -131.0, memory_length 2000, epsilon 0.9848166021822828\n",
      "state terminated\n",
      "episode 52, reward -162.0, memory_length 2000, epsilon 0.984521204513494\n",
      "state terminated\n",
      "episode 53, reward -271.0, memory_length 2000, epsilon 0.9842258954507143\n",
      "state terminated\n",
      "episode 54, reward -302.0, memory_length 2000, epsilon 0.9839306749673656\n",
      "state terminated\n",
      "episode 55, reward -200.0, memory_length 2000, epsilon 0.9836355430368785\n",
      "state terminated\n",
      "episode 56, reward -66.0, memory_length 2000, epsilon 0.9833404996326909\n",
      "state terminated\n",
      "episode 57, reward -222.0, memory_length 2000, epsilon 0.9830455447282489\n",
      "state terminated\n",
      "episode 58, reward 6.0, memory_length 2000, epsilon 0.9827506782970066\n",
      "state terminated\n",
      "episode 59, reward 106.0, memory_length 2000, epsilon 0.982455900312426\n",
      "state terminated\n",
      "episode 60, reward 122.0, memory_length 2000, epsilon 0.9821612107479771\n",
      "state terminated\n",
      "episode 61, reward -311.0, memory_length 2000, epsilon 0.9818666095771379\n",
      "state terminated\n",
      "episode 62, reward -318.0, memory_length 2000, epsilon 0.9815720967733942\n",
      "state terminated\n",
      "episode 63, reward -5.0, memory_length 2000, epsilon 0.9812776723102398\n",
      "state terminated\n",
      "episode 64, reward -429.0, memory_length 2000, epsilon 0.9809833361611765\n",
      "state terminated\n",
      "episode 65, reward -243.0, memory_length 2000, epsilon 0.9806890882997144\n",
      "state terminated\n",
      "episode 66, reward -353.0, memory_length 2000, epsilon 0.9803949286993706\n",
      "state terminated\n",
      "episode 67, reward -407.0, memory_length 2000, epsilon 0.9801008573336712\n",
      "state terminated\n",
      "episode 68, reward -17.0, memory_length 2000, epsilon 0.9798068741761496\n",
      "state terminated\n",
      "episode 69, reward -133.0, memory_length 2000, epsilon 0.9795129792003474\n",
      "state terminated\n",
      "episode 70, reward -364.0, memory_length 2000, epsilon 0.9792191723798138\n",
      "state terminated\n",
      "episode 71, reward -89.0, memory_length 2000, epsilon 0.9789254536881066\n",
      "state terminated\n",
      "episode 72, reward -59.0, memory_length 2000, epsilon 0.9786318230987908\n",
      "state terminated\n",
      "episode 73, reward -189.0, memory_length 2000, epsilon 0.9783382805854397\n",
      "state terminated\n",
      "episode 74, reward -350.0, memory_length 2000, epsilon 0.9780448261216346\n",
      "state terminated\n",
      "episode 75, reward -220.0, memory_length 2000, epsilon 0.9777514596809644\n",
      "state terminated\n",
      "episode 76, reward -160.0, memory_length 2000, epsilon 0.9774581812370263\n",
      "state terminated\n",
      "episode 77, reward 90.0, memory_length 2000, epsilon 0.9771649907634252\n",
      "state terminated\n",
      "episode 78, reward 171.0, memory_length 2000, epsilon 0.9768718882337739\n",
      "state terminated\n",
      "episode 79, reward -276.0, memory_length 2000, epsilon 0.9765788736216932\n",
      "state terminated\n",
      "episode 80, reward -152.0, memory_length 2000, epsilon 0.9762859469008117\n",
      "state terminated\n",
      "episode 81, reward -635.0, memory_length 2000, epsilon 0.9759931080447662\n",
      "state terminated\n",
      "episode 82, reward 94.0, memory_length 2000, epsilon 0.975700357027201\n",
      "state terminated\n",
      "episode 83, reward -132.0, memory_length 2000, epsilon 0.9754076938217687\n",
      "state terminated\n",
      "episode 84, reward -448.0, memory_length 2000, epsilon 0.9751151184021294\n",
      "state terminated\n",
      "episode 85, reward -207.0, memory_length 2000, epsilon 0.9748226307419514\n",
      "state terminated\n",
      "episode 86, reward -298.0, memory_length 2000, epsilon 0.974530230814911\n",
      "state terminated\n",
      "episode 87, reward -18.0, memory_length 2000, epsilon 0.9742379185946918\n",
      "state terminated\n",
      "episode 88, reward -168.0, memory_length 2000, epsilon 0.9739456940549861\n",
      "state terminated\n",
      "episode 89, reward -100.0, memory_length 2000, epsilon 0.9736535571694933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 90, reward -416.0, memory_length 2000, epsilon 0.9733615079119216\n",
      "state terminated\n",
      "episode 91, reward -126.0, memory_length 2000, epsilon 0.9730695462559861\n",
      "state terminated\n",
      "episode 92, reward -576.0, memory_length 2000, epsilon 0.9727776721754104\n",
      "state terminated\n",
      "episode 93, reward -190.0, memory_length 2000, epsilon 0.9724858856439259\n",
      "state terminated\n",
      "episode 94, reward 93.0, memory_length 2000, epsilon 0.9721941866352718\n",
      "state terminated\n",
      "episode 95, reward -257.0, memory_length 2000, epsilon 0.9719025751231951\n",
      "state terminated\n",
      "episode 96, reward -276.0, memory_length 2000, epsilon 0.9716110510814508\n",
      "state terminated\n",
      "episode 97, reward -231.0, memory_length 2000, epsilon 0.9713196144838019\n",
      "state terminated\n",
      "episode 98, reward -51.0, memory_length 2000, epsilon 0.9710282653040188\n",
      "state terminated\n",
      "episode 99, reward -165.0, memory_length 2000, epsilon 0.9707370035158802\n",
      "state terminated\n",
      "episode 100, reward -29.0, memory_length 2000, epsilon 0.9704458290931727\n",
      "state terminated\n",
      "episode 101, reward -109.0, memory_length 2000, epsilon 0.9701547420096904\n",
      "state terminated\n",
      "episode 102, reward 20.0, memory_length 2000, epsilon 0.9698637422392355\n",
      "state terminated\n",
      "episode 103, reward -118.0, memory_length 2000, epsilon 0.9695728297556182\n",
      "state terminated\n",
      "episode 104, reward -154.0, memory_length 2000, epsilon 0.9692820045326561\n",
      "state terminated\n",
      "episode 105, reward -245.0, memory_length 2000, epsilon 0.9689912665441751\n",
      "state terminated\n",
      "episode 106, reward 26.0, memory_length 2000, epsilon 0.9687006157640088\n",
      "state terminated\n",
      "episode 107, reward -144.0, memory_length 2000, epsilon 0.9684100521659985\n",
      "state terminated\n",
      "episode 108, reward -293.0, memory_length 2000, epsilon 0.9681195757239935\n",
      "state terminated\n",
      "episode 109, reward -162.0, memory_length 2000, epsilon 0.9678291864118511\n",
      "state terminated\n",
      "episode 110, reward -374.0, memory_length 2000, epsilon 0.9675388842034361\n",
      "state terminated\n",
      "episode 111, reward 105.0, memory_length 2000, epsilon 0.9672486690726213\n",
      "state terminated\n",
      "episode 112, reward -11.0, memory_length 2000, epsilon 0.9669585409932874\n",
      "state terminated\n",
      "episode 113, reward -104.0, memory_length 2000, epsilon 0.9666684999393228\n",
      "state terminated\n",
      "episode 114, reward 89.0, memory_length 2000, epsilon 0.9663785458846238\n",
      "state terminated\n",
      "episode 115, reward -331.0, memory_length 2000, epsilon 0.9660886788030947\n",
      "state terminated\n",
      "episode 116, reward -60.0, memory_length 2000, epsilon 0.9657988986686473\n",
      "state terminated\n",
      "episode 117, reward -37.0, memory_length 2000, epsilon 0.9655092054552015\n",
      "state terminated\n",
      "episode 118, reward 67.0, memory_length 2000, epsilon 0.9652195991366846\n",
      "state terminated\n",
      "episode 119, reward -30.0, memory_length 2000, epsilon 0.9649300796870326\n",
      "state terminated\n",
      "episode 120, reward -232.0, memory_length 2000, epsilon 0.9646406470801883\n",
      "state terminated\n",
      "episode 121, reward -62.0, memory_length 2000, epsilon 0.9643513012901027\n",
      "state terminated\n",
      "episode 122, reward -304.0, memory_length 2000, epsilon 0.964062042290735\n",
      "state terminated\n",
      "episode 123, reward -105.0, memory_length 2000, epsilon 0.9637728700560518\n",
      "state terminated\n",
      "episode 124, reward -297.0, memory_length 2000, epsilon 0.9634837845600276\n",
      "state terminated\n",
      "episode 125, reward 93.0, memory_length 2000, epsilon 0.9631947857766446\n",
      "state terminated\n",
      "episode 126, reward -14.0, memory_length 2000, epsilon 0.9629058736798929\n",
      "state terminated\n",
      "episode 127, reward -248.0, memory_length 2000, epsilon 0.9626170482437706\n",
      "state terminated\n",
      "episode 128, reward -217.0, memory_length 2000, epsilon 0.9623283094422832\n",
      "state terminated\n",
      "episode 129, reward -290.0, memory_length 2000, epsilon 0.9620396572494443\n",
      "state terminated\n",
      "episode 130, reward -124.0, memory_length 2000, epsilon 0.9617510916392753\n",
      "state terminated\n",
      "episode 131, reward -208.0, memory_length 2000, epsilon 0.9614626125858051\n",
      "state terminated\n",
      "episode 132, reward 119.0, memory_length 2000, epsilon 0.9611742200630707\n",
      "state terminated\n",
      "episode 133, reward -276.0, memory_length 2000, epsilon 0.9608859140451168\n",
      "state terminated\n",
      "episode 134, reward -86.0, memory_length 2000, epsilon 0.9605976945059957\n",
      "state terminated\n",
      "episode 135, reward -108.0, memory_length 2000, epsilon 0.9603095614197679\n",
      "state terminated\n",
      "episode 136, reward -385.0, memory_length 2000, epsilon 0.9600215147605011\n",
      "state terminated\n",
      "episode 137, reward -1.0, memory_length 2000, epsilon 0.9597335545022715\n",
      "state terminated\n",
      "episode 138, reward 153.0, memory_length 2000, epsilon 0.9594456806191622\n",
      "state terminated\n",
      "episode 139, reward -451.0, memory_length 2000, epsilon 0.959157893085265\n",
      "state terminated\n",
      "episode 140, reward 212.0, memory_length 2000, epsilon 0.9588701918746788\n",
      "state terminated\n",
      "episode 141, reward 81.0, memory_length 2000, epsilon 0.9585825769615105\n",
      "state terminated\n",
      "episode 142, reward -280.0, memory_length 2000, epsilon 0.9582950483198748\n",
      "state terminated\n",
      "episode 143, reward 125.0, memory_length 2000, epsilon 0.958007605923894\n",
      "state terminated\n",
      "episode 144, reward 44.0, memory_length 2000, epsilon 0.9577202497476984\n",
      "state terminated\n",
      "episode 145, reward -122.0, memory_length 2000, epsilon 0.9574329797654261\n",
      "state terminated\n",
      "episode 146, reward 7.0, memory_length 2000, epsilon 0.9571457959512224\n",
      "state terminated\n",
      "episode 147, reward 83.0, memory_length 2000, epsilon 0.9568586982792411\n",
      "state terminated\n",
      "episode 148, reward 81.0, memory_length 2000, epsilon 0.9565716867236432\n",
      "state terminated\n",
      "episode 149, reward 160.0, memory_length 2000, epsilon 0.9562847612585978\n",
      "state terminated\n",
      "episode 150, reward 40.0, memory_length 2000, epsilon 0.9559979218582816\n",
      "state terminated\n",
      "episode 151, reward 62.0, memory_length 2000, epsilon 0.9557111684968789\n",
      "state terminated\n",
      "episode 152, reward 141.0, memory_length 2000, epsilon 0.9554245011485821\n",
      "state terminated\n",
      "episode 153, reward -171.0, memory_length 2000, epsilon 0.9551379197875911\n",
      "state terminated\n",
      "episode 154, reward -243.0, memory_length 2000, epsilon 0.9548514243881134\n",
      "state terminated\n",
      "episode 155, reward -41.0, memory_length 2000, epsilon 0.9545650149243646\n",
      "state terminated\n",
      "episode 156, reward -266.0, memory_length 2000, epsilon 0.9542786913705679\n",
      "state terminated\n",
      "episode 157, reward 29.0, memory_length 2000, epsilon 0.9539924537009539\n",
      "state terminated\n",
      "episode 158, reward -180.0, memory_length 2000, epsilon 0.9537063018897614\n",
      "state terminated\n",
      "episode 159, reward -158.0, memory_length 2000, epsilon 0.9534202359112368\n",
      "state terminated\n",
      "episode 160, reward -27.0, memory_length 2000, epsilon 0.953134255739634\n",
      "state terminated\n",
      "episode 161, reward 18.0, memory_length 2000, epsilon 0.9528483613492148\n",
      "state terminated\n",
      "episode 162, reward -146.0, memory_length 2000, epsilon 0.952562552714249\n",
      "state terminated\n",
      "episode 163, reward -182.0, memory_length 2000, epsilon 0.9522768298090133\n",
      "state terminated\n",
      "episode 164, reward -441.0, memory_length 2000, epsilon 0.9519911926077932\n",
      "state terminated\n",
      "episode 165, reward -284.0, memory_length 2000, epsilon 0.9517056410848808\n",
      "state terminated\n",
      "episode 166, reward 46.0, memory_length 2000, epsilon 0.9514201752145769\n",
      "state terminated\n",
      "episode 167, reward -426.0, memory_length 2000, epsilon 0.9511347949711894\n",
      "state terminated\n",
      "episode 168, reward 76.0, memory_length 2000, epsilon 0.950849500329034\n",
      "state terminated\n",
      "episode 169, reward -356.0, memory_length 2000, epsilon 0.9505642912624344\n",
      "state terminated\n",
      "episode 170, reward -479.0, memory_length 2000, epsilon 0.9502791677457216\n",
      "state terminated\n",
      "episode 171, reward -153.0, memory_length 2000, epsilon 0.9499941297532346\n",
      "state terminated\n",
      "episode 172, reward -239.0, memory_length 2000, epsilon 0.9497091772593198\n",
      "state terminated\n",
      "episode 173, reward -243.0, memory_length 2000, epsilon 0.9494243102383316\n",
      "state terminated\n",
      "episode 174, reward 2.0, memory_length 2000, epsilon 0.9491395286646321\n",
      "state terminated\n",
      "episode 175, reward -356.0, memory_length 2000, epsilon 0.9488548325125907\n",
      "state terminated\n",
      "episode 176, reward -87.0, memory_length 2000, epsilon 0.9485702217565849\n",
      "state terminated\n",
      "episode 177, reward 38.0, memory_length 2000, epsilon 0.9482856963709998\n",
      "state terminated\n",
      "episode 178, reward 40.0, memory_length 2000, epsilon 0.9480012563302278\n",
      "state terminated\n",
      "episode 179, reward -79.0, memory_length 2000, epsilon 0.9477169016086697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 180, reward -82.0, memory_length 2000, epsilon 0.9474326321807333\n",
      "state terminated\n",
      "episode 181, reward -313.0, memory_length 2000, epsilon 0.9471484480208344\n",
      "state terminated\n",
      "episode 182, reward -153.0, memory_length 2000, epsilon 0.9468643491033965\n",
      "state terminated\n",
      "episode 183, reward -461.0, memory_length 2000, epsilon 0.9465803354028507\n",
      "state terminated\n",
      "episode 184, reward 3.0, memory_length 2000, epsilon 0.9462964068936357\n",
      "state terminated\n",
      "episode 185, reward -186.0, memory_length 2000, epsilon 0.946012563550198\n",
      "state terminated\n",
      "episode 186, reward -207.0, memory_length 2000, epsilon 0.9457288053469916\n",
      "state terminated\n",
      "episode 187, reward 278.0, memory_length 2000, epsilon 0.9454451322584783\n",
      "state terminated\n",
      "episode 188, reward -159.0, memory_length 2000, epsilon 0.9451615442591275\n",
      "state terminated\n",
      "episode 189, reward -118.0, memory_length 2000, epsilon 0.9448780413234165\n",
      "state terminated\n",
      "episode 190, reward 63.0, memory_length 2000, epsilon 0.9445946234258297\n",
      "state terminated\n",
      "episode 191, reward -50.0, memory_length 2000, epsilon 0.9443112905408597\n",
      "state terminated\n",
      "episode 192, reward -253.0, memory_length 2000, epsilon 0.9440280426430064\n",
      "state terminated\n",
      "episode 193, reward -316.0, memory_length 2000, epsilon 0.9437448797067777\n",
      "state terminated\n",
      "episode 194, reward -81.0, memory_length 2000, epsilon 0.9434618017066888\n",
      "state terminated\n",
      "episode 195, reward -124.0, memory_length 2000, epsilon 0.9431788086172626\n",
      "state terminated\n",
      "episode 196, reward -101.0, memory_length 2000, epsilon 0.94289590041303\n",
      "state terminated\n",
      "episode 197, reward -216.0, memory_length 2000, epsilon 0.9426130770685289\n",
      "state terminated\n",
      "episode 198, reward -140.0, memory_length 2000, epsilon 0.9423303385583053\n",
      "state terminated\n",
      "episode 199, reward -89.0, memory_length 2000, epsilon 0.9420476848569129\n",
      "state terminated\n",
      "episode 200, reward -363.0, memory_length 2000, epsilon 0.9417651159389129\n",
      "state terminated\n",
      "episode 201, reward -153.0, memory_length 2000, epsilon 0.9414826317788739\n",
      "state terminated\n",
      "episode 202, reward 184.0, memory_length 2000, epsilon 0.9412002323513723\n",
      "state terminated\n",
      "episode 203, reward 61.0, memory_length 2000, epsilon 0.9409179176309923\n",
      "state terminated\n",
      "episode 204, reward 13.0, memory_length 2000, epsilon 0.9406356875923255\n",
      "state terminated\n",
      "episode 205, reward -204.0, memory_length 2000, epsilon 0.9403535422099712\n",
      "state terminated\n",
      "episode 206, reward 19.0, memory_length 2000, epsilon 0.9400714814585365\n",
      "state terminated\n",
      "episode 207, reward -59.0, memory_length 2000, epsilon 0.9397895053126356\n",
      "state terminated\n",
      "episode 208, reward -324.0, memory_length 2000, epsilon 0.9395076137468908\n",
      "state terminated\n",
      "episode 209, reward -90.0, memory_length 2000, epsilon 0.939225806735932\n",
      "state terminated\n",
      "episode 210, reward -107.0, memory_length 2000, epsilon 0.9389440842543963\n",
      "state terminated\n",
      "episode 211, reward 96.0, memory_length 2000, epsilon 0.9386624462769289\n",
      "state terminated\n",
      "episode 212, reward 214.0, memory_length 2000, epsilon 0.9383808927781824\n",
      "state terminated\n",
      "episode 213, reward 103.0, memory_length 2000, epsilon 0.9380994237328167\n",
      "state terminated\n",
      "episode 214, reward -189.0, memory_length 2000, epsilon 0.9378180391154998\n",
      "state terminated\n",
      "episode 215, reward 0.0, memory_length 2000, epsilon 0.9375367389009072\n",
      "state terminated\n",
      "episode 216, reward -125.0, memory_length 2000, epsilon 0.9372555230637216\n",
      "state terminated\n",
      "episode 217, reward -99.0, memory_length 2000, epsilon 0.9369743915786337\n",
      "state terminated\n",
      "episode 218, reward -280.0, memory_length 2000, epsilon 0.9366933444203417\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-37db32d0bd6d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m                             reward, env.state_encod_arch1(next_state))\n\u001b[0;32m     34\u001b[0m         \u001b[1;31m# 4. Train the model by calling function agent.train_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[1;31m# 5. Keep a track of rewards, Q-values, loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mscore\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-33-c9c594583fdc>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m                 \u001b[1;31m# 2. Get the target for the Q-network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m                 \u001b[0mtarget_qval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mupdate_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m                 \u001b[1;31m# 3. Update your 'update_output' and 'update_input' batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfod\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1745\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1746\u001b[0m       \u001b[0mbatch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1747\u001b[1;33m       \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Single epoch.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1748\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1749\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfod\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1180\u001b[1;33m       \u001b[0mdata_iterator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1181\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfod\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    409\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 411\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    412\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfod\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[0;32m    694\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcomponents\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0melement_spec\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 696\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    697\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_create_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfod\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    717\u001b[0m               \u001b[0moutput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m               output_shapes=self._flat_output_shapes))\n\u001b[1;32m--> 719\u001b[1;33m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    720\u001b[0m       \u001b[1;31m# Delete the resource when this object is deleted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m       self._resource_deleter = IteratorResourceDeleter(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfod\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[1;34m(dataset, iterator, name)\u001b[0m\n\u001b[0;32m   3118\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3119\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m-> 3120\u001b[1;33m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[0m\u001b[0;32m   3121\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3122\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "rewards_per_episode, episodes, avg_rewards_per_episode = [], [], []\n",
    "\n",
    "env = CabDriver()\n",
    "agent = DQNAgent(action_size=len(env.action_space), state_size=len(env.state_encod_arch1(\n",
    "    env.state_init)))\n",
    "\n",
    "for episode in range(Episodes):\n",
    "\n",
    "    # Write code here\n",
    "    # Call the environment\n",
    "    env = CabDriver()\n",
    "    score = 0\n",
    "    # Call all the initialised variables of the environment\n",
    "    action_space, state_space, state = env.reset()\n",
    "\n",
    "    terminal_state = False\n",
    "    t = 0\n",
    "    count = 1\n",
    "    while not terminal_state:\n",
    "        #print(\"count = {}\".format(count))\n",
    "        count += 1\n",
    "        # Write your code here\n",
    "        # 1. Pick epsilon-greedy action from possible actions for the current state\n",
    "        possible_actions_index, actions = env.requests(state)\n",
    "        action_index, action = agent.get_action(env.state_encod_arch1(state), env.action_space, possible_actions_index)\n",
    "        # 2. Evaluate your reward and next state\n",
    "        next_state, wait_time, transit_time, ride_time = env.next_state_func(state, action,\n",
    "                                                                             Time_matrix)\n",
    "        reward = env.reward_func(state, action, Time_matrix)\n",
    "        # 3. Append the experience to the memory\n",
    "        agent.append_sample(env.state_encod_arch1(state), action_index,\n",
    "                            reward, env.state_encod_arch1(next_state))\n",
    "        # 4. Train the model by calling function agent.train_model\n",
    "        agent.train_model()\n",
    "        # 5. Keep a track of rewards, Q-values, loss\n",
    "        score += reward\n",
    "        state = next_state\n",
    "        t += wait_time + transit_time + ride_time\n",
    "        #print(t)\n",
    "        # TODO Do we need a logic to make sure that total time never goes more than 30 days. Which\n",
    "        # TODO requires last ride to be less than the time left\n",
    "        # TODO OR we not very hard strict with 30 days, driver can even work extra few hour just\n",
    "        # TODO because of last ride\n",
    "        if t >= 24 * 30:\n",
    "            print(\"state terminated\")\n",
    "            terminal_state = True\n",
    "\n",
    "    # store total reward obtained in this episode\n",
    "    rewards_per_episode.append(score)\n",
    "    episodes.append(episode)\n",
    "\n",
    "    # epsilon decay\n",
    "    if agent.epsilon > agent.epsilon_min:\n",
    "        agent.epsilon = agent.epsilon_min + (agent.epsilon_max - agent.epsilon_min) * np.exp(-agent.epsilon_decay*episode)\n",
    "\n",
    "    # every episode:\n",
    "    print(\"episode {0}, reward {1}, memory_length {2}, epsilon {3}\".format(episode,\n",
    "                                                                           score,\n",
    "                                                                           len(agent.memory),\n",
    "                                                                           agent.epsilon))\n",
    "    # every few episodes:\n",
    "    if episode % 10 == 0:\n",
    "        # store q-values of some prespecified state-action pairs\n",
    "        agent.store_q_values()\n",
    "    if episode % 1000 == 0:\n",
    "        agent.save(\"model.pkl\")\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print('Total time taken ',elapsed_time)\n",
    "### TODO Keep a track of Q-values, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elapsed_time = time.time() - start_time\n",
    "print('Total time taken ',elapsed_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Tracking Convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Convergence by tracking total rewards per episode vs episode number\n",
    "plt.plot(list(range(len(rewards_per_episode))), rewards_per_episode)\n",
    "plt.ylabel(\"total rewards\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-193.19, -71.4, 6.7, 69.84, 182.68, 299.27, 366.65, 464.41, 529.81, 617.89, 683.02, 743.45, 821.31, 878.89, 972.36, 1016.66, 1088.72, 1095.04, 1183.8, 1167.81, 1304.96, 1328.43, 1379.78, 1367.21, 1445.3, 1522.36, 1533.08, 1602.25, 1593.58, 1660.5, 1657.14, 1673.9, 1733.91, 1726.08, 1832.4, 1793.37, 1878.21, 1884.69, 1896.17, 1910.96, 1966.37, 1969.01, 1969.95, 2022.73, 2064.84, 2057.83, 2063.7, 2124.19, 2150.17, 2172.7, 2150.63, 2169.52, 2205.83, 2207.24, 2241.26, 2261.91, 2262.2, 2294.77, 2287.56, 2337.6, 2323.99, 2327.4, 2367.36, 2394.08, 2381.1, 2391.88, 2378.43, 2398.06, 2437.44, 2424.45, 2432.12, 2450.84, 2464.57, 2484.94, 2477.26, 2484.41, 2479.57, 2521.54, 2535.41, 2530.25, 2542.37, 2557.09, 2555.66, 2561.55, 2562.28, 2553.48, 2577.65, 2600.7, 2581.16, 2569.36, 2576.22, 2593.51, 2626.65, 2623.33, 2625.29, 2631.17, 2642.36, 2626.88, 2632.11, 2643.78, 2642.74, 2671.84, 2662.69, 2647.11, 2655.5, 2665.8, 2665.17, 2660.2, 2668.96, 2669.79, 2672.05, 2696.88, 2686.92, 2691.98, 2690.01, 2696.79, 2692.01, 2695.11, 2713.09, 2701.3, 2706.42, 2708.47, 2700.37, 2714.58, 2702.22, 2704.72, 2704.54, 2710.28, 2713.23, 2712.67, 2718.85, 2722.37, 2728.4, 2715.08, 2713.21, 2729.88, 2716.02, 2726.86, 2724.29, 2725.83, 2724.6, 2728.61, 2733.98, 2723.51, 2739.54, 2732.12, 2737.24, 2729.24, 2738.83, 2735.57, 2736.92, 2742.19, 2747.79, 2744.36, 2730.02, 2735.18, 2739.3, 2742.29, 2739.57, 2745.04, 2747.29, 2741.38, 2748.11, 2744.09, 2748.08, 2746.76, 2739.72, 2738.51, 2744.34, 2738.7, 2745.49, 2749.38, 2743.86, 2754.06, 2744.78, 2744.67, 2792.27, 2806.97, 2807.24, 2804.42, 2798.7, 2788.0, 2799.21, 2796.8, 2795.45, 2804.76, 2793.94, 2799.7, 2800.51, 2799.37, 2804.89, 2795.55, 2796.91, 2799.02, 2789.51, 2804.62, 2800.49, 2803.35, 2806.17, 2797.04]\n"
     ]
    }
   ],
   "source": [
    "# Average reward per 100 episode\n",
    "avg_rewards = []\n",
    "episodes = len(rewards_per_episode)\n",
    "index = 0\n",
    "track_total_reward = 0\n",
    "for episode_number in range(episodes):\n",
    "    if index != 100:\n",
    "        track_total_reward += rewards_per_episode[episode_number]\n",
    "        index += 1\n",
    "    else:\n",
    "        avg_rewards.append(track_total_reward/index)\n",
    "        track_total_reward = rewards_per_episode[episode_number]\n",
    "        index = 1\n",
    "\n",
    "avg_rewards.append(track_total_reward/index)\n",
    "        \n",
    "    \n",
    "print(avg_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAD8CAYAAABgmUMCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xd8XOWd7/HPT11Ws2TJtmRZbgg3wLgAJpRASEIJLY1LyYaUDZtdyCbbWZJd2HCzN7spu7DJJksSb8zeEMoFgpOQgCHZhVCMK+5F7pJlSVbvbX73jzkmwrbsGVszo/J9v156aeaZM3N+OhrNV+d5nnOOuTsiIiKRSkp0ASIiMrIoOEREJCoKDhERiYqCQ0REoqLgEBGRqCg4REQkKgoOERGJioJDRESiouAQEZGopCS6gFgoLCz06dOnJ7oMEZERZe3atUfcvehUy43K4Jg+fTpr1qxJdBkiIiOKme2PZDl1VYmISFQUHCIiEhUFh4iIREXBISIiUVFwiIhIVBQcIiISFQWHiIhEZVQexyEiEk9VTZ38bH0V3b395GamMrVgHIvK8inKST/h8l29/azd38g5JXnkjUslFHK6+voJOaSnJLHjcCuNHT0snTmB1OTj/7/fVdNKQ3sPZRPGcaS1h6qmDho7ennv2UWUjM+M9Y+r4BARORNPrD7AP/x8Kx09/cc9tqhsPB86r4TnNlSxp66d/KxUCrLS2V/fTlNHL1lpycwryWVjZTPdfaHjnj8xJ53JeRk0dvTQ1NHLnMk5zCzM5sm1B3E/vpYkg2vPLeY7ty3EzGLx4wIKDhGR03agvoP7nt3MhdML+OePnUdpfibNnb3srmtn1d56Hn/rIA/+YiszCrP42OJSGjt6aGjv4fLyIq6eP5mVWw+z90g7t19UxqTcDAzo7O1nRmEW6SnJPLehio6efmYWZpGTkcqru+pYva+RT148jSvnTKSysZOi7HRK8zPJSE3iuQ2HCLnHNDQAzE8UWyPckiVLXKccEZFYu/fpjTyzvopX//pKJuVmHPd4X3+Iiro2yifmkJx05h/moZDT2t1HXmbqGb/WiZjZWndfcqrltMchIgnlEfyH3N3Xz+aqZlbva6ShvYcZhVlce85kxo9Le2eZ5o5eDjZ2kJmWTFpyEusPNnGgvp3O3n4WTs2nqbOXzVXNlOZn4g776ttJT0lmRlEWV5xdRHFeBnVt3WysbGb6hCwyU5N5ZVcd26pb6OzpZ15JLr/dUcuOw21cf14xsyZm8/S6Sm69oOyEoQGQkpzEnMm5Q7atkpIsZqERDQWHiESlsb2HHTWtLCwbT3pKMgB76tqobOzksvJCunpD7G9oZ2JOBn39Ibr7QmSkJnOgoYNNlU1srW5hZlE2syfl8A8/30Jnbz8XzpjA7to2sjNSuHB6Ab/ecpia5i6m5GfS0x+isrGTnmAMIC05iZ7+EN94YQcfW1zKnro2NlU1U9PSfcJ6kwxCQcdKRmoSXb3h1xk/LpWevtAJxyYGys1IIS0lmWfWV1Gcl8HiaeN5bNUBevpDZKQm8fkrZg3Rlh051FUlMorVt3VT29rN3OLj/+t1d97YU09JXibTC7Pe9VhrVy97j7RT29JNUhLsqWtn1d4Gdte2sbe+HXcoKxjHpy+ZTmdvPw+9tIvuvhCLp+Wzp66Nxo7eQWsaPy6VpuDxaRPGMWdyDhsONlE+MYeali521bZx/tTxnFeax6GmLtJTkyjJy2DJ9AIWT8unYFwaWw618MDPt7DuQCOzirI5d0oec4tzKCsYR2dvP+3d/Zw/dTxnTcwG4O2DTWSlpzC/JJf69h6SzCjICu+t7K5r47WKIzS295KdkcL5U/PYU9dOR08/l5UXMiPYNjUt3UzITiM1OYm27j5aOnvJSk8ZFnsAQyXSrioFh8gI4+5U1LYxqyibpAH95r39IXbVtFFakEl2Wgqv767nS0+s50hbD5eVF+IOu2pbaWzvZf6UXFKTk3hrbwPJScb75kykuy9Ed28/rV19bD/c8s5/6UfNLMxi9uQc5hbnUlYwjn//7wp21rQBcFl5IZeXF7Hstb3ML8nlQ+cV09TRS0pyEhkpSXT09FOcl8F5peOZlJvO1uoWNlY2c+OCErLS393x0dzZG/GHcU9fiLQUHY42VBQcCg4ZhdydB1ZsYfkb+5lZlMXU/HHsrGklKz2FmpYuWrv6gN9358wsyuL680p4as1B8selMa8kl7zMVF7fXU9tSxdfeN9Z7D3SzsvbaynISiMjNZn0lCQWluUzvySXybkZhNyZnJdBcd67jw8IhZy6tm7au/uYPiHrXSEmI5OCQ8Ehw9hbextYva+Bm84voTR/3Dvt3X397D3STmpyElPGZ5Jkxis769hX305zZy8VtW38avNhblxQwqGmTtq6+5hbnEtnTz95malcNLOAQ02dtAYf5jcsKCE7XUOZEhnNqhIZpvbUtfHZH6+mtbuPb764gzsuKuPOi6fzq82H+a8391PXGh7kTUkyMtOS39mLMIPcjFQ+e+kMvvKhuTGfqy8yGAWHyBBzd1btbeC322v5+JJSzpqYQ31bNz/63V42VTWzp66d1JQknvr0xfxyYzXL39jH/33zABAeK7jvujkYxs6aVurberjm3MksKssnJz1F3UEyLCg4RM5AZWMHP3x1L5PzMkhJMiobO3ljdz07aloB+M/X93HelDw2VTXT0x9ifkkuhTnp3HftHC6YXsAF0wu4YUEJbx9s4gPzJjG1YNwp1iiSeAoOkdPU1x/iCz9dz4aDTe+cNygjNYnF0/L5xNL5XDF7It96cQf76ju446Jp3H7RVM6amHPc6yyels/iaflxrl7k9Ck4RE6iqqmTL/50PVfOmcifXDHrXeMKD/+mgvUHmnj4toVcMbsIgJz0lHct86+3Lox7zSKxpuAQGcTh5i5u/8GbVDZ2smZ/I1urW/i7D80jJdn4xq938MSag3x44RRuXFCS6FJF4krBIWNaKOQkJRmN7T1sONhES1cvBVlpzCrK5o4frqK+rYenPn8xb+yu519W7uTFLYfpC46Mu/vKWfzZ+89O8E8gEn8KDhmTuvv6+fff7ub7/7Mbd+gNhd51fYMkg8zUZB797IUsKstnUVk+Ny4oYfnr+8jJSOWacyYze/Lx4xUiY0HMgsPMpgKPApMABx5x94fM7AHgc0BdsOh97v588Jy/BT4L9AN/6u4vBO3XAA8BycAP3f3rsapbRqfe/hBPrD7IkbZuCrLS+OGreznQ0MF1506mrCCLrLRkLpxRQGFOOrtqWnlhSw13XFTG4mkF77zG1IJxfOX6eQn8KUSGh1jucfQBf+Hu68wsB1hrZiuDx/7F3b85cGEzmwfcCswHSoCXzOxoP8B3gQ8AlcBqM1vh7ltjWLuMIlVNnXxq2Vvsqm3DDNxhXnEuj37mQi4/u+i45WcVZXPNOcUJqFRkZIhZcLh7NVAd3G41s23AlJM85SbgcXfvBvaaWQVwYfBYhbvvATCzx4NlFRwSkX/85TYqGzv5wSeXcPGsCRxs6GD2pBwdTCdymuJyWkkzmw4sBFYFTfeY2UYzW2ZmRyewTwEODnhaZdA2WPux67jLzNaY2Zq6urpjH5YxoKcvxI7DrfT1h+jo6WNzVTOv7z7CLzdVc9flM/nAvElkp6cwtzhXoSFyBmI+OG5m2cDTwJfcvcXMvgc8SHjc40HgW8BnznQ97v4I8AiET3J4pq8nI0tDew9/uHw16w40UZCVRnt3H93BhX+KctK56/KZCa5QZPSIaXCYWSrh0PiJuz8D4O41Ax7/AfCL4G4VMHXA00uDNk7SLsJvttdw/4ot1LR081dXz6aito28zFQWlo1nd107F8+ccNw1H0Tk9MVyVpUBPwK2ufu3B7QXB+MfAB8GNge3VwCPmdm3CQ+OlwNvAQaUm9kMwoFxK3B7rOqW4a21q5fs4Ojsrt5+vvzsZp5eV8msoix++rmlOnWHSBzE8t+wS4A/ADaZ2Yag7T7gNjM7n3BX1T7gjwDcfYuZPUl40LsPuNvd+wHM7B7gBcLTcZe5+5YY1i3DVEVtK9f/2++YPSmHa88t5mfrq9h+uJUvXlXO3VeepSvBicSJLuQkI4K788llb7HhYBNZaSkcbuli9qQc/urq2bx/3qRElycyKuhCTjIi1bZ00dMfojR/HD19IRwnPSWZX2ys5tVdR3jghnncemEZ9e09TBmfeeoXFJEhp+CQYeNQUycf/vfXqG/r4epzJvPm7np6+kPcsKCEJ1cf5LzSPD6xdBopwWVVRSQxFBwyLLR39/GZH6+mo7ufmxdOYcWGQ1xy1gT6HR5bdYD3nl3Ed25fSEqyxjFEEk3BIcPCw7/ZxfbDre+cBuSbH18AhMc2dte1MaMwm2QdtCcyLCg4JCF+vTk8I/vq+ZPZV9/Bst/t5WOLS487d5SZnfCqeSKSOAoOibvali7+9Kcb6OkPMbc4l8b2HtJTkvnra2YnujQRiYA6jCXufvTaXvpCIf7yg2eTnpLEgql5/NvtC5mYk5Ho0kQkAtrjkLhwd772y2309Id4dl0V155bzD3vK+ee95UnujQRiZKCQ+Ji+ev7+OHv9pKabPSFnD9+76xElyQip0nBITHTH3L+87W97DnSzv9bW8lVcybyndsXUdvaxbQJWYkuT0ROk4JDYqKrt58vPr6eF7bUUJCVxtziXP7pY+eRmZas0BAZ4RQcEhP3PbuJF7fW8PfXz+Mzl85IdDkiMoQ0q0qG3AtbDvPMuiq+cOVZCg2RUUh7HDJknlx9kG+8uIOG9h7ml+RqxpTIKKXgkCGx70g7f/fcZuZMzuHji0u5Y+k0XR9DZJRScMhpOdLWzbde3MntF5YxpziH+57dRFpyEv/xB0uYnKcD+URGMwWHRK22pYvbf7iKito2fv72IWZPzmHt/ka+/pFzFRoiY4D6EiQqTR093PHDVVQ3dfLwbQuZmJvOpqpmvn3LAm69sCzR5YlIHGiPQyLW0xfic4+uYX99Bz/+zAW8Z1Yh75szkZbOXkp0YSWRMUPBIRH71eZqVu9r5Nu3LOA9swoByE5PITtdbyORsURdVRKxJ9ccZGpBJjefPyXRpYhIAik4JCIHGzp4raKejy+eSpKuxCcypqmPQQb1/KZq9td3sHhaPo+/dQAz+Oji0kSXJSIJpuCQE6ps7OBLT2ygpy/0TttHF5UyRYPgImNezILDzKYCjwKTAAcecfeHzKwAeAKYDuwDbnH3RjMz4CHgOqAD+JS7rwte607gK8FL/293Xx6ruiXsWy/uxICf3X0Jh5u7mFucQ1nBuESXJSLDQCz3OPqAv3D3dWaWA6w1s5XAp4CX3f3rZnYvcC/wN8C1QHnwdRHwPeCiIGjuB5YQDqC1ZrbC3RtjWPuYtuVQM8+ur+KPr5jF+VPHw9REVyQiw0nMBsfdvfroHoO7twLbgCnATcDRPYblwM3B7ZuARz3sTWC8mRUDVwMr3b0hCIuVwDWxqlvgB6/sISstmc/rKn0icgJxmVVlZtOBhcAqYJK7VwcPHSbclQXhUDk44GmVQdtg7ceu4y4zW2Nma+rq6oa0/rGkpqWLX2ys5pYLppKXmZrockRkGIr54LiZZQNPA19y95bwUEaYu7uZ+VCsx90fAR4BWLJkyZC85ljR2dPP7ro26tq6+cXb1fS786n3TE90WSIyTMU0OMwslXBo/MTdnwmaa8ys2N2rg66o2qC9inf3ppcGbVXAFce0/3cs6x5LevtD3PCd31FR2/ZO23XnTtblXUVkULGcVWXAj4Bt7v7tAQ+tAO4Evh58f25A+z1m9jjhwfHmIFxeAP7RzPKD5T4I/G2s6h5rVm6toaK2jb+5Zg4XzSxgXFoyMwoVGiIyuFjucVwC/AGwycw2BG33EQ6MJ83ss8B+4JbgsecJT8WtIDwd99MA7t5gZg8Cq4PlvuruDTGse0xZ/vo+SvMzuevymSTriHARiUDMgsPdfwcM9kl01QmWd+DuQV5rGbBs6KoTgM1Vzaza28C9185RaIhIxHTk+BjU1dvP8tf38a8v7SIvM5VbluhADRGJnIJjDNlU2cyKt6v42YZD1LV28745E3nw5nMoyEpLdGkiMoIoOMaIhvYePvr918HhPWdN4PPvncXSmRMSXZaIjEAKjjHitYoj9PSFePqPL2bxtIJElyMiI5iuxzHK7axppa8/xKu76sjNSGFB6fhElyQiI5z2OEaxmpYurn3oVT558TRe3XWES8sLSUnW/woicmb0KTKKrdvfSH/I+fHr+6hu7uKy8qJElyQio4CCYxRbf7CJtOSkd05WeOlZhQmuSERGA3VVjWLrDzRyzpRc7rp8Fq/uqmOqLsQkIkNAwTFK9faH2FjZzCeWTuOacyZzzTmTE12SiIwSUXVVmVm+mZ0Xq2Jk6GyvbqW7LxS+gp+IyBA65R6Hmf03cGOw7Fqg1sxec/c/j3Ftchpau3r58yffprWrF4CFZQoOERlakXRV5QUXYPpDwpd2vd/MNsa6MDk9z204xMqtNSQnGaX5mUwZn5nokkRklIkkOFKCCy7dAnw5xvXIGXpyzUHmTM7h8buW0h9yBl5xUURkKEQyxvFV4AWgwt1Xm9lMYFdsy5LTsfVQCxsrm/lfF0xl/Lg0JmSnJ7okERmFTrnH4e5PAU8NuL8H+Ggsi5LodfT08e2VO0lLTuLm86ckuhwRGcUGDQ4z+zfAB3vc3f80JhVJVB5YsYXnN1VjBrWt3fz11XPI12nSRSSGTrbHsSb4fgkwD3giuP9xYGssi5LItHb18thbB5hZmEVxXgbfvmUml+jocBGJsUGDw92XA5jZHwOXuntfcP/7wKvxKU9O5sUtNfT0hfjah89l8bT8RJcjImNEJIPj+UDugPvZQZskSE9fiJ6+ECvePsSU8Zks0rEaIhJHkUzH/Tqw3sx+CxhwOfBALIuSk7tz2Vtsrmqmo7efz102U1NuRSSuThocFv5Eegn4FXBR0Pw37n441oXJiR1s6OCNPfXMLc6lvbuPW5aUJrokERljThoc7u5m9ry7nws8F6ea5CSe31QNwH98YjFlE3S2WxGJv0jGONaZ2QUxr0Qi8stN1SwozVNoiEjCRBIcFwFvmNluM9toZpsiOVeVmS0zs1oz2zyg7QEzqzKzDcHXdQMe+1szqzCzHWZ29YD2a4K2CjO7N9ofcDR5Y3c9Gyub+dB5xYkuRUTGsEgGx68+9SIn9GPgO8Cjx7T/i7t/c2CDmc0DbgXmAyXAS2Z2dvDwd4EPAJXAajNb4e5j7jiSe5/eyOOrDzIhK40bF+jIcBFJnEhOObIfwMwmAhmRvrC7v2Jm0yNc/CbgcXfvBvaaWQVwYfBYRXCaE8zs8WDZMRUcje09PLnmIB9ZOIWv3nwO2em6/paIJM4pu6rM7EYz2wXsBf4H2Ed4ltXpuifo8lpmZkePB5kCHBywTGXQNlj7ieq8y8zWmNmaurq6Myhv+PnvnbWEHO58z3SFhogkXCRjHA8CS4Gd7j4DuAp48zTX9z1gFnA+UA186zRf5zju/oi7L3H3JUVFRUP1ssPCS9tqKcpJ59wpeYkuRUQkouDodfd6IMnMktz9t8CS01mZu9e4e7+7h4Af8PvuqCpg6oBFS4O2wdrHjJ6+EK/sqON9syeSlKQD/UQk8SIJjiYzywZeAX5iZg8B7aezsuCCUEd9GDg642oFcKuZpZvZDKAceAtYDZSb2QwzSyM8gL7idNY9Uq3e10Brdx9XzZ2Y6FJERIDIZlXdBHQCfwbcAeQRvrjTSZnZT4ErgEIzqwTuB64ws/MJn659H/BHAO6+xcyeJDzo3Qfc7e79wevcQ/hCUsnAMnffEsXPN+K9vK2WtJQkLi3XWW9FZHiIJDhuBV5x913A8khf2N1vO0Hzj06y/NeAr52g/Xng+UjXO5q4Oy9vr+E9syYwLk2D4iIyPETSVVUG/IeZ7TWzp8zsC8Feg8TY7ro29td3cNXcSYkuRUTkHZEcx3E/gJllAp8D/gr4V8JdRxIDTR09/GZ7LQcbOgG4ao7GN0Rk+DhlcJjZVwhfBTAbWA/8JbqQU0x9/VfbeXx1+PCVecW5lIzPTHBFIiK/F0nH+UcID1j/kvABgG8ER3hLDNS1dvPMuiqunF1Ev8NNC0oSXZKIyLtE0lW1yMxyCe91fAB4xMxq3f3SmFc3Bv3XG/voDYX4u+vnMbMoO9HliIgcJ5KuqnOAy4D3Ej7w7yDqqoqJrYda+M/X9/H+uZMUGiIybEV66dhXgYeB1e7eG9uSxqbddW3c8cM3yU5P4e+vn5fockREBhVJV9X1wYyqMoVG7Px01QHae/p59k8uYWqBLtIkIsNXJGfHvQHYAPw6uH++mY2p037Ew46aVs6elM30wqxElyIiclKRHAD4AOGTETYBuPsGYEYMaxqTdtW0cfaknESXISJySpGeHbf5mDaPRTFjVXNnL4dbuhQcIjIiRDI4vsXMbgeSzawc+FPg9diWNbbsqmkF4OxJmkklIsNfJHscXyB8LfBu4DGgGfhSLIsaa3YEwVE+UXscIjL8nXSPw8ySga+6+18CX45PSWPPrpo2stKSmaJTi4jICHDS4HD3fjPTEeIxsqeujVV7G9h6qIWzJuXoCn8iMiJEMsaxPph++xQDrvzn7s/ErKox4lsrd/LLjdUAfHxxaYKrERGJTCTBkQHUA+8b0OaAguMMhELOG7vrOXdKHs2dvVypU6eLyAgRyZHjn45HIWPN9sOtNLT3cN91c/mY9jZEZASJZFaVxMDru48AcMlZExJciYhIdBQcCfL67npmFmZRnKeZVCIysig44qy1q5dH39jHm3vqeY/2NkRkBIrkehx/foLmZmBtcN4qicJXfraZ5zYcoqxgHHdcNC3R5YiIRC2SWVVLgq+fB/evBzYCnzezp9z9n2NV3GjT1dvPyq013HrBVP7PR87FTMdtiMjIE0lwlAKL3L0NwMzuJ3z98cuBtYCCI0Kv7Kyjo6efD51XrNAQkRErkjGOiYTPU3VULzDJ3TuPaX8XM1tmZrVmtnlAW4GZrTSzXcH3/KDdzOxhM6sws41mtmjAc+4Mlt9lZndG/RMOI7/efJi8zFSWztTYhoiMXJEEx0+AVWZ2f7C38RrwmJllAVtP8rwfA9cc03Yv8LK7lwMvB/cBrgXKg6+7gO9BOGiA+4GLCF8T5P6jYTPS9PSFeGlbDe+fO4nUZM1JEJGR65SfYO7+IOEP86bg6/Pu/lV3b3f3O07yvFeAhmOabwKWB7eXAzcPaH/Uw94ExptZMXA1sNLdG9y9EVjJ8WE0IjyzrpKWrj5uWFCc6FJERM5IJLOqHgYed/eHhmB9k9y9Orh9GJgU3J4CHBywXGXQNlj7ieq8i3DAUVZWNgSlDp2u3n4eenkXC8vG896zixJdjojIGYmkz2Qt8BUz221m3zSzJUOxYnd3hvBKgu7+iLsvcfclRUXD68P5sVUHqG7u4q+unq1BcREZ8SLpqlru7tcBFwA7gH8ys12nub6aoAuK4Htt0F4FTB2wXGnQNlj7iPLchirOnzqe98wqTHQpIiJnLJpR2rOAOcA0YPtprm8FcHRm1J3AcwPaPxnMrloKNAddWi8AHzSz/GBQ/INB24jR2tXL5kMtXFau0BCR0SGSMY5/Bj4M7AaeAB5096YInvdT4Aqg0MwqCc+O+jrwpJl9FtgP3BIs/jxwHVABdACfBnD3BjN7EFgdLPdVdz92wH1YW7O/kf6QawquiIwakRwAuBu42N2PRPPC7n7bIA9ddYJlHbh7kNdZBiyLZt3Dyao9DaQmG4vKRuQsYhGR40RyPY7/CLqKLiR8Uaej7a/EtLJR4s099SwoHU9mWnKiSxERGRKnHOMwsz8EXiE8tvAPwfcHYlvW6NDe3cemqmZ1U4nIqBLJ4PgXCc+o2u/uVwILCR8IKKfw0rYa+kOu06eLyKgSSXB0uXsXgJmlu/t2YHZsyxodHlt1gLKCcSydoeAQkdEjksHxSjMbD/wMWGlmjYRnRMlJVNS2sWpvA39zzRySknTQn4iMHpEMjn84uPmAmf0WyAN+HdOqRoHH3zpAarLx8SWliS5FRGRIRbLH8Q53/59YFTKauDu/3FTNlbMnUpidnuhyRESGlM7vHQPbqlupbu7i/fMmnXphEZERRsERAy9vq8EMrpw9MdGliIgMOQVHDLy8vZYFpeMpylE3lYiMPgqOIVbX2s3blU1cNUd7GyIyOik4htivNlfjDh+Yr/ENERmdFBxD7Ol1VcwtzmXO5NxElyIiEhMKjiFUUdvG2web+OiiE17dVkRkVFBwDKGn11WSnGTcdL6CQ0RGLwXHEOkPOT9bX8V7zy7SbCoRGdUUHEPkjd31VDd38dFFOsWIiIxuCo4h8vS6SnIzUrhqrqbhisjopuAYAm3dffx682GuX1BCRqqu9Ccio5uCYwi8vK2Gzt5+PrJQg+IiMvopOIbAaxVHyMtMZWFZfqJLERGJOQXHGXJ3Xquo5+KZE0jWBZtEZAxQcJyh/fUdVDV1ckl5YaJLERGJCwXHGfpdxREALpml64qLyNiQkOAws31mtsnMNpjZmqCtwMxWmtmu4Ht+0G5m9rCZVZjZRjNblIiaB/P67iOU5GUwozAr0aWIiMRFIvc4rnT38919SXD/XuBldy8HXg7uA1wLlAdfdwHfi3ulg+jq7efVnUe4rLwIM41viMjYMJy6qm4Clge3lwM3D2h/1MPeBMabWXEiCjzWb7bX0trdxw0LShJdiohI3CQqOBx40czWmtldQdskd68Obh8Gjl7QYgpwcMBzK4O2dzGzu8xsjZmtqauri1Xd7/LchiqKctK5WOMbIjKGpCRovZe6e5WZTQRWmtn2gQ+6u5uZR/OC7v4I8AjAkiVLonru6Wju6OW32+v4xNJpmoYrImNKQvY43L0q+F4LPAtcCNQc7YIKvtcGi1cBUwc8vTRoS6iXttXQ0x/ipvPVTSUiY0vcg8PMssws5+ht4IPAZmAFcGew2J3Ac8HtFcAng9lVS4HmAV1aCfPmnnrGj0vl3Cl5iS5FRCSuEtFVNQl4NpiFlAI85u6/NrPVwJNm9llgP3BLsPzzwHVg5mp8AAAIkklEQVRABdABfDr+JR9vzf5GlkwrIEndVCIyxsQ9ONx9D7DgBO31wFUnaHfg7jiUFrHa1i72HmnntgunnnphEZFRZjhNxx0x1uxrBOCC6QUJrkREJP4UHKdh9b4GMlKTmF+i8Q0RGXsUHKdh9b4GFk7NJy1Fm09Exh598kWpqqmTzVUtXKqz4YrIGKXgiNIv3j4EwPXnDYuznoiIxJ2CI0o/33iIBVPHM22CzoYrImOTgiMKe+ra2FzVwg3a2xCRMUzBEYWXttUA8CEFh4iMYQqOKLxd2UxpfibFeZmJLkVEJGEUHFHYXNXMeaU6dkNExjYFR4SaO3rZX9/BuVPGJ7oUEZGEUnBEaFNVM4D2OERkzFNwRGhjVRMA5+g0IyIyxik4IrSpsplpE8aRNy410aWIiCSUgiNCGyubddEmEREUHBFpaO+hqqlT4xsiIig4InJ0YFwzqkREFBwR2VQZHhifPyU3wZWIiCSegiMCGyubmVmYRW6GBsZFRBQcEdhU1cy5Gt8QEQEUHKdU29pFdXOXZlSJiAQUHKew+Z2BcQWHiAgoOE5p9b5GkgzmKzhERAAFx0mFQs6KDYe4tLyI7PSURJcjIjIsjJjgMLNrzGyHmVWY2b3xWOdb+xqoaurko4umxGN1IiIjwogIDjNLBr4LXAvMA24zs3mxXu8z6yrJTk/hg/Mmx3pVIiIjxogIDuBCoMLd97h7D/A4cFMsV9jV28/zmw5z7TmTyUxLjuWqRERGlJESHFOAgwPuVwZt7zCzu8xsjZmtqaurO+MVvrmnnrbuPl1fXETkGCMlOE7J3R9x9yXuvqSoqOiMX+8322vJTE1m6cwJQ1CdiMjoMVKCowqYOuB+adAWE+7Oy9tqubS8kIxUdVOJiAw0UoJjNVBuZjPMLA24FVgRq5XtrGmjqqmTq+ZMjNUqRERGrBFxcIK795nZPcALQDKwzN23xGp9v9leC8CVCg4RkeOMiOAAcPfngefjsa71BxqZWZTFpNyMeKxORGREGSldVXG15VAL80t0ihERkRNRcByjqSN8mdj5Jbpok4jIiSg4jrH1UAsA84oVHCIiJ6LgOMaWIDi0xyEicmIKjmNsOdTM5NwMJmSnJ7oUEZFhScFxjC2HWpinvQ0RkUEpOAbo6u1nd12buqlERE5CwTFAa1cf159XwkUzdH4qEZHBjJgDAOOhKCedh29bmOgyRESGNe1xiIhIVBQcIiISFQWHiIhERcEhIiJRUXCIiEhUFBwiIhIVBYeIiERFwSEiIlExd090DUPOzOqA/WfwEoXAkSEqZyiprugM17pg+NamuqIzXOuC06ttmrsXnWqhURkcZ8rM1rj7kkTXcSzVFZ3hWhcM39pUV3SGa10Q29rUVSUiIlFRcIiISFQUHCf2SKILGITqis5wrQuGb22qKzrDtS6IYW0a4xARkahoj0NERKKi4BjAzK4xsx1mVmFm9yawjqlm9lsz22pmW8zsi0H7A2ZWZWYbgq/rElTfPjPbFNSwJmgrMLOVZrYr+J4f55pmD9guG8ysxcy+lIhtZmbLzKzWzDYPaDvh9rGwh4P33EYzWxTnur5hZtuDdT9rZuOD9ulm1jlgu30/VnWdpLZBf3dm9rfBNtthZlfHua4nBtS0z8w2BO1x22Yn+YyIz/vM3fUV7q5LBnYDM4E04G1gXoJqKQYWBbdzgJ3APOAB4C+HwbbaBxQe0/bPwL3B7XuBf0rw7/IwMC0R2wy4HFgEbD7V9gGuA34FGLAUWBXnuj4IpAS3/2lAXdMHLpegbXbC313wt/A2kA7MCP5uk+NV1zGPfwv4+3hvs5N8RsTlfaY9jt+7EKhw9z3u3gM8DtyUiELcvdrd1wW3W4FtwJRE1BKFm4Dlwe3lwM0JrOUqYLe7n8lBoKfN3V8BGo5pHmz73AQ86mFvAuPNrDhedbn7i+7eF9x9EyiNxbpPZZBtNpibgMfdvdvd9wIVhP9+41qXmRlwC/DTWKz7ZE7yGRGX95mC4/emAAcH3K9kGHxYm9l0YCGwKmi6J9jVXBbv7qABHHjRzNaa2V1B2yR3rw5uHwYmJaY0AG7l3X/Mw2GbDbZ9htP77jOE/ys9aoaZrTez/zGzyxJU04l+d8Nlm10G1Lj7rgFtcd9mx3xGxOV9puAYxswsG3ga+JK7twDfA2YB5wPVhHeTE+FSd18EXAvcbWaXD3zQw/vGCZmuZ2ZpwI3AU0HTcNlm70jk9hmMmX0Z6AN+EjRVA2XuvhD4c+AxM8uNc1nD7nd3jNt49z8ocd9mJ/iMeEcs32cKjt+rAqYOuF8atCWEmaUSfkP8xN2fAXD3Gnfvd/cQ8ANitHt+Ku5eFXyvBZ4N6qg5uusbfK9NRG2Ew2ydu9cENQ6Lbcbg2yfh7zsz+xRwPXBH8GFD0A1UH9xeS3gc4ex41nWS391w2GYpwEeAJ462xXubnegzgji9zxQcv7caKDezGcF/rbcCKxJRSNB3+iNgm7t/e0D7wD7JDwObj31uHGrLMrOco7cJD65uJryt7gwWuxN4Lt61Bd71X+Bw2GaBwbbPCuCTwayXpUDzgK6GmDOza4C/Bm50944B7UVmlhzcngmUA3viVVew3sF+dyuAW80s3cxmBLW9Fc/agPcD29298mhDPLfZYJ8RxOt9Fo8ZACPli/DMg52E/1P4cgLruJTwLuZGYEPwdR3wX8CmoH0FUJyA2mYSntHyNrDl6HYCJgAvA7uAl4CCBNSWBdQDeQPa4r7NCAdXNdBLuC/5s4NtH8KzXL4bvOc2AUviXFcF4b7vo++z7wfLfjT4/W4A1gE3JGCbDfq7A74cbLMdwLXxrCto/zHw+WOWjds2O8lnRFzeZzpyXEREoqKuKhERiYqCQ0REoqLgEBGRqCg4REQkKgoOERGJioJDRESiouAQEZGoKDhERCQq/x9+zVnCNa5nPQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Check Convergence by tracking average rewards per episode vs episode number\n",
    "plt.plot(list(range(len(avg_rewards))), avg_rewards)\n",
    "plt.ylabel(\"avg rewards\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(0, figsize=(16,7))\n",
    "plt.title('Q_value for state [0,0,0]  action (0,2)')\n",
    "xaxis = np.asarray(range(0, len(agent.states_tracked)))\n",
    "plt.semilogy(xaxis,np.asarray(agent.states_tracked))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Epsilon-decay sample function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Try building a similar epsilon-decay function for your model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.arange(0,10000)\n",
    "epsilon = []\n",
    "for i in range(0,10000):\n",
    "    epsilon.append(0 + (1 - 0) * np.exp(-0.0003*i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(time, epsilon)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
